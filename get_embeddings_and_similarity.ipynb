{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f8ac0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import copy\n",
    "import argparse\n",
    "import imageio\n",
    "from PIL import Image\n",
    "import glob\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import skimage\n",
    "import tqdm\n",
    "from tensorflow.python.platform import gfile\n",
    "import nbimporter\n",
    "import align.detect_face\n",
    "from keras.models import load_model\n",
    "from get_most_important_features import get_most_important_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b61a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD MODEL\n",
    "\n",
    "def get_model_filenames(model_dir):\n",
    "    print(os.getcwd())\n",
    "    files = os.listdir(model_dir)\n",
    "    meta_files = [s for s in files if s.endswith('.meta')]\n",
    "    if len(meta_files)==0:\n",
    "        raise ValueError('No meta file found in the model directory (%s)' % model_dir)\n",
    "    elif len(meta_files)>1:\n",
    "        raise ValueError('There should not be more than one meta file in the model directory (%s)' % model_dir)\n",
    "    meta_file = meta_files[0]\n",
    "    ckpt = tf.train.get_checkpoint_state(model_dir)\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        ckpt_file = os.path.basename(ckpt.model_checkpoint_path)\n",
    "        return meta_file, ckpt_file\n",
    "\n",
    "    meta_files = [s for s in files if '.ckpt' in s]\n",
    "    max_step = -1\n",
    "    for f in files:\n",
    "        step_str = re.match(r'(^model-[\\w\\- ]+.ckpt-(\\d+))', f)\n",
    "        if step_str is not None and len(step_str.groups())>=2:\n",
    "            step = int(step_str.groups()[1])\n",
    "            if step > max_step:\n",
    "                max_step = step\n",
    "                ckpt_file = step_str.groups()[0]\n",
    "    return meta_file, ckpt_file\n",
    "\n",
    "\n",
    "\n",
    "def load_model(model, input_map=None):\n",
    "    # Check if the model is a model directory (containing a metagraph and a checkpoint file)\n",
    "    #  or if it is a protobuf file with a frozen graph\n",
    "    model_exp = os.path.expanduser(model)\n",
    "    print(os.path.isfile(model_exp))\n",
    "    if (os.path.isfile(model_exp)):\n",
    "        print('Model filename: %s' % model_exp)\n",
    "        with gfile.FastGFile(model_exp,'rb') as f:\n",
    "            graph_def = tf.GraphDef()\n",
    "            graph_def.ParseFromString(f.read())\n",
    "            tf.import_graph_def(graph_def, input_map=input_map, name='')\n",
    "    else:\n",
    "        print('Model directory: %s' % model_exp)\n",
    "        meta_file, ckpt_file = get_model_filenames(model_exp)\n",
    "        \n",
    "        print('Metagraph file: %s' % meta_file)\n",
    "        print('Checkpoint file: %s' % ckpt_file)\n",
    "      \n",
    "        saver = tf.train.import_meta_graph(os.path.join(model_exp, meta_file), input_map=input_map)\n",
    "        saver.restore(tf.get_default_session(), os.path.join(model_exp, ckpt_file))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc7ea7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RESHAPE (160x160)\n",
    "\n",
    "def prewhiten(x):\n",
    "    mean = np.mean(x)\n",
    "    std = np.std(x)\n",
    "    std_adj = np.maximum(std, 1.0/np.sqrt(x.size))\n",
    "    y = np.multiply(np.subtract(x, mean), 1/std_adj)\n",
    "    return y              \n",
    "\n",
    "\n",
    "#Gives images of dimension 160 for inference, and of 60 for explanation. \n",
    "def load_and_align_data(image_paths, image_size, margin = 44, gpu_memory_fraction = 1.0):\n",
    "    print(image_paths)\n",
    "    minsize = 20 # minimum size of face\n",
    "    threshold = [ 0.6, 0.7, 0.7 ]  # three steps's threshold\n",
    "    factor = 0.709 # scale factor\n",
    "    \n",
    "    print('Creating networks and loading parameters')\n",
    "    with tf.Graph().as_default():\n",
    "        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=gpu_memory_fraction)\n",
    "        sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options, log_device_placement=False))\n",
    "        with sess.as_default():\n",
    "            pnet, rnet, onet = align.detect_face.create_mtcnn(sess, None)\n",
    "  \n",
    "    tmp_image_paths=copy.copy(image_paths)\n",
    "    img_list = []\n",
    "    for image in glob.glob(os.path.expanduser(image_paths)): #(tmp_image_paths)\n",
    "        img = imageio.imread(os.path.expanduser(image), pilmode='RGB')\n",
    "        img_size = np.asarray(img.shape)[0:2]\n",
    "        bounding_boxes, _ = align.detect_face.detect_face(img, minsize, pnet, rnet, onet, threshold, factor)\n",
    "        if len(bounding_boxes) < 1:\n",
    "            image_paths.remove(image)\n",
    "            print(\"can't detect face, remove \", image)\n",
    "            continue\n",
    "        det = np.squeeze(bounding_boxes[0,0:4])\n",
    "        bb = np.zeros(4, dtype=np.int32)\n",
    "        bb[0] = np.maximum(det[0]-margin/2, 0)\n",
    "        bb[1] = np.maximum(det[1]-margin/2, 0)\n",
    "        bb[2] = np.minimum(det[2]+margin/2, img_size[1])\n",
    "        bb[3] = np.minimum(det[3]+margin/2, img_size[0])\n",
    "        cropped = img[bb[1]:bb[3],bb[0]:bb[2],:]\n",
    "        aligned = np.array(Image.fromarray(cropped).resize((image_size, image_size)))\n",
    "        #aligned = misc.imresize(cropped, (image_size, image_size), interp='bilinear')\n",
    "        prewhitened = prewhiten(aligned)\n",
    "        img_list.append(prewhitened)\n",
    "    \n",
    "    img_list_60 = []\n",
    "    for img in img_list:\n",
    "        img_list_60.append(skimage.transform.resize(img, (60,60)))\n",
    "    \n",
    "    \n",
    "    images = np.stack(img_list)\n",
    "    images_60 = np.stack(img_list_60)\n",
    "    return images, images_60\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3844c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#READ FROM FOLDER\n",
    "#img_path = os.getcwd() + \"\\data\\*\"\n",
    "#print(img_path)\n",
    "#images = load_and_align_data(img_path, 160)\n",
    "\n",
    "def get_embeddings(save = False, df = None, path = None, image_list = None):\n",
    "    #save = True si se desea guardar los embedding en un df.\n",
    "    # Si las imagenes están guardadas en un dataframe X, poner df = X\n",
    "    # Si las imágenes están en una carpeta poner path = ubicación carpeta\n",
    "    # Si las imágenes están en una lista t = [i1, i2, i3, ...] poner image_list = t\n",
    "    \n",
    "    #Entrega dos outputs. Una lista de las imágenes con dimensiones (60x60) y una lista de los embeddings asociados a cada imagen.\n",
    "    \n",
    "    \n",
    "    if df is not None:\n",
    "        df = pd.read_pickle('celeb40_cropped_identities_pickle' )# '\\src\\lfw_pickle')\n",
    "        images_60 = list(df[\"images\"])#Erase last in brackets\n",
    "        images = []\n",
    "        for i in range(len(images_60)):\n",
    "            images.append(skimage.transform.resize(images_60[i], (160,160)) )\n",
    "\n",
    "    \n",
    "    \n",
    "    if path is not None: #READ FROM FOLDER\n",
    "        images, images_60 = load_and_align_data(path, 160)\n",
    "\n",
    "        \n",
    "    if image_list is not None:\n",
    "        images_60 = image_list\n",
    "        images = []\n",
    "        for i in range(len(images_60)):\n",
    "            images.append(skimage.transform.resize(images_60[i], (160,160)) )\n",
    "\n",
    "        \n",
    "        \n",
    "            \n",
    "    images = np.stack(images)\n",
    "    batch_size = 100\n",
    "    n_images = len(images)\n",
    "    print(n_images)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    with tf.Graph().as_default():\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "\n",
    "            # Load the model\n",
    "            load_model(\"20180402-114759.pb\")\n",
    "\n",
    "            # Get input and output tensors\n",
    "            batch_size_placeholder = tf.placeholder(tf.int32, name='batch_size')\n",
    "\n",
    "            images_placeholder = tf.get_default_graph().get_tensor_by_name(\"input:0\")\n",
    "            embeddings = tf.get_default_graph().get_tensor_by_name(\"embeddings:0\")\n",
    "            phase_train_placeholder = tf.get_default_graph().get_tensor_by_name(\"phase_train:0\")\n",
    "\n",
    "            # Run forward pass to calculate embeddings\n",
    "            emb = np.ndarray((n_images, 512))*0\n",
    "            i = 0\n",
    "\n",
    "            while i*batch_size + batch_size <= n_images:\n",
    "                feed_dict = {images_placeholder: images[i* batch_size : i* batch_size + batch_size], phase_train_placeholder:False }#, batch_size_placeholder:batch_size}\n",
    "                emb[i* batch_size : i*batch_size + batch_size] = sess.run(embeddings, feed_dict=feed_dict)\n",
    "                i += 1\n",
    "\n",
    "\n",
    "\n",
    "            feed_dict = {images_placeholder: images[i* batch_size : n_images], phase_train_placeholder:False }#, batch_size_placeholder:batch_size}\n",
    "            emb[i* batch_size : n_images] = sess.run(embeddings, feed_dict=feed_dict)\n",
    "            #emb[i* batch_size : n_images] = \n",
    "            #print(type(emb))\n",
    "            print(emb.shape)\n",
    "            #print(emb)\n",
    "            \n",
    "            if save:\n",
    "                #emb_df = df[[\"person\", 'imagenum']]\n",
    "                #emb_df[\"embeddings\"] = list(emb)\n",
    "                df = pd.DataFrame({\"embeddings\": list(emb)})#ERASE FOR LFW\n",
    "                df.to_pickle(\"celeb40_cropped_embeddings_pickle\")\n",
    "            else:\n",
    "                return images_60, emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65836a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EJEMPLO\n",
    "\n",
    "images, embeddings = get_embeddings(save = False,  image_list = images[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd563701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EL output es un cuadro donde se muestra la similaridad según la métrica especificada \n",
    "\n",
    "\n",
    "emb = embeddings\n",
    "nrof_images = len(images)\n",
    "\n",
    "print('Distance matrix')\n",
    "print('    ', end='')\n",
    "for i in range(nrof_images):\n",
    "    print('    %1d     ' % i, end='')\n",
    "print('')\n",
    "for i in range(nrof_images):\n",
    "    print('%1d  ' % i, end='')\n",
    "    for j in range(nrof_images):\n",
    "        #ESPECIFICACIÓN DE MÉTRICA DE DISTANCIA. La siguiente es el dot.product normalizado, pero se puede cambiar a otras, como cos similarity.\n",
    "        dist =  np.dot(emb[i,:], emb[j,:])/(np.linalg.norm(emb[i,:])*np.linalg.norm(emb[j,:]))\n",
    "        \n",
    "        \n",
    "        #Comentar la línea de código anterior y agregar la siguiente indicando un valor para el threshold sobre el cuál las imágenes se consideran de la misma categoría,\n",
    "        # y por debajo del cuál se consideran de categoría diferente\n",
    "        # El output que se obtendrá será una matriz con un valor de 1 si las imágenes son de la misma categoría, y 0 si son de categoría diferente:\n",
    "        \n",
    "        # dist =  np.dot(emb[i,:], emb[j,:])/(np.linalg.norm(emb[i,:])*np.linalg.norm(emb[j,:])) > threshold\n",
    "        \n",
    "        print('  %1.4f  ' % dist, end='')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b54e01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
